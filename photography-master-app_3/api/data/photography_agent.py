#!/usr/bin/env python3
"""
æ‰‹æœºæ‘„å½±æŒ‡å¯¼Agent
ç»“åˆOpenCVç²¾ç¡®æ°´å¹³æ£€æµ‹å’Œè§†è§‰ç†è§£çš„ä¼˜åŠ¿
"""

import json
import base64
import os
import hashlib
from typing import Dict, List
from PIL import Image
import cv2
import numpy as np
import math
from config import Config
from openai import OpenAI

class PhotographyAgent:
    def __init__(self, knowledge_file: str = "extracted_photography_knowledge.json"):
        Config.validate_config()
        self.model_name = Config.MODEL_NAME
        self.client = OpenAI(
            base_url=Config.OPENROUTER_BASE_URL,
            api_key=Config.OPENROUTER_API_KEY,
        )
        
        # æ·»åŠ ç¼“å­˜æœºåˆ¶
        self.cache = {}
        self.cache_file = "ai_cache.json"
        self.load_cache()
        
        # æ·»åŠ æ¶ˆæ¯å†å²è®°å½•
        self.message_history = []
        self.max_history_length = 10  # ä¿æŒæœ€è¿‘10æ¡æ¶ˆæ¯
        
        # æ·»åŠ ä¼šè¯çŠ¶æ€ç®¡ç†
        self.session_started = False
        self.user_photography_intent = None  # ç”¨æˆ·æƒ³æ‹æ‘„çš„å†…å®¹
        
        # æ— éœ€åŠ è½½é¢å¤–æ£€æµ‹å™¨
        
        # åŠ è½½çŸ¥è¯†åº“
        self.extracted_knowledge = self.load_extracted_knowledge(knowledge_file)
        print(f"å·²åŠ è½½ {len(self.extracted_knowledge)} ä¸ªç²¾ç®€çŸ¥è¯†ç‚¹")
    
    def load_cache(self):
        """åŠ è½½ç¼“å­˜"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                print(f"å·²åŠ è½½ {len(self.cache)} æ¡ç¼“å­˜è®°å½•")
        except Exception as e:
            print(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            self.cache = {}
    
    def save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        try:
            # åªä¿ç•™æœ€è¿‘100æ¡ç¼“å­˜
            if len(self.cache) > 100:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜
                oldest_keys = sorted(self.cache.keys(), key=lambda k: self.cache[k].get('timestamp', 0))[:len(self.cache) - 100]
                for key in oldest_keys:
                    del self.cache[key]
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def get_cache_key(self, image_path: str, analysis: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        try:
            # åŸºäºå›¾ç‰‡æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´ç”Ÿæˆé”®
            stat = os.stat(image_path)
            key_data = f"{stat.st_size}_{stat.st_mtime}_{analysis.get('brightness', 0):.1f}_{analysis.get('is_level', True)}"
            return hashlib.md5(key_data.encode()).hexdigest()
        except:
            return hashlib.md5(image_path.encode()).hexdigest()
    
    def get_cached_result(self, cache_key: str):
        """è·å–ç¼“å­˜ç»“æœ"""
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ24å°æ—¶ï¼‰
            import time
            if time.time() - cached_data.get('timestamp', 0) < 86400:
                print(f"ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return cached_data.get('result')
        return None
    
    def set_cached_result(self, cache_key: str, result):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        import time
        self.cache[cache_key] = {
            'result': result,
            'timestamp': time.time()
        }
    
    def add_to_message_history(self, role: str, content: str, image_data: str = None):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•"""
        message = {"role": role}
        
        if role == "user" and image_data:
            # ç”¨æˆ·æ¶ˆæ¯åŒ…å«å›¾ç‰‡
            message["content"] = [
                {"type": "text", "text": content},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
            ]
        else:
            # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
            message["content"] = content
        
        self.message_history.append(message)
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.message_history) > self.max_history_length:
            self.message_history = self.message_history[-self.max_history_length:]
        
        print(f"æ·»åŠ æ¶ˆæ¯åˆ°å†å² (è§’è‰²: {role}, å†å²é•¿åº¦: {len(self.message_history)})")
    
    def clear_message_history(self):
        """æ¸…ç©ºæ¶ˆæ¯å†å²è®°å½•"""
        self.message_history = []
        self.session_started = False
        self.user_photography_intent = None
        print("å·²æ¸…ç©ºæ¶ˆæ¯å†å²è®°å½•å’Œä¼šè¯çŠ¶æ€")
    
    def get_message_history_summary(self):
        """è·å–æ¶ˆæ¯å†å²è®°å½•æ‘˜è¦"""
        return {
            "total_messages": len(self.message_history),
            "messages_preview": [
                {
                    "role": msg["role"],
                    "has_image": isinstance(msg.get("content"), list) and any(
                        item.get("type") == "image_url" for item in msg.get("content", [])
                    ),
                    "text_preview": (
                        msg["content"][:50] + "..." if isinstance(msg["content"], str) and len(msg["content"]) > 50
                        else (
                            msg["content"][0]["text"][:50] + "..." if isinstance(msg.get("content"), list) and len(msg["content"]) > 0 and "text" in msg["content"][0] and len(msg["content"][0]["text"]) > 50
                            else (
                                msg["content"][0]["text"] if isinstance(msg.get("content"), list) and len(msg["content"]) > 0 and "text" in msg["content"][0]
                                else msg["content"] if isinstance(msg["content"], str)
                                else "No text content"
                            )
                        )
                    )
                }
                for msg in self.message_history[-5:]  # æ˜¾ç¤ºæœ€å5æ¡æ¶ˆæ¯
            ]
        }
    
    def start_conversation(self):
        """å¼€å§‹æ–°çš„æ‹æ‘„ä¼šè¯"""
        if not self.session_started:
            self.session_started = True
            self.clear_message_history()
            
            # æ·»åŠ åˆå§‹å¯¹è¯
            greeting_message = """ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIæ‘„å½±åŠ©æ‰‹ ğŸ“¸

åœ¨å¼€å§‹æ‹æ‘„ä¹‹å‰ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼šä½ æƒ³æ‹æ‘„ä»€ä¹ˆå†…å®¹å‘¢ï¼Ÿ

æ¯”å¦‚ï¼š
ğŸŒ… é£æ™¯ç…§ç‰‡ï¼ˆæ—¥å‡ºã€å±±æ™¯ã€æµ·æ™¯ç­‰ï¼‰
ğŸ‘¤ äººåƒç…§ç‰‡ï¼ˆæœ‹å‹ã€å®¶äººã€è‡ªæ‹ç­‰ï¼‰  
ğŸ• ç¾é£Ÿç…§ç‰‡ï¼ˆé¤å…èœå“ã€å®¶å¸¸èœç­‰ï¼‰
ğŸ—ï¸ å»ºç­‘ç…§ç‰‡ï¼ˆå¤å»ºç­‘ã€ç°ä»£å»ºç­‘ç­‰ï¼‰
ğŸŒ¸ èŠ±è‰ç…§ç‰‡ï¼ˆå…¬å›­ã€èŠ±å›­ç­‰ï¼‰
ğŸ± å® ç‰©ç…§ç‰‡
ğŸ“š äº§å“ç…§ç‰‡ï¼ˆç‰©å“å±•ç¤ºç­‰ï¼‰

æˆ–è€…å…¶ä»–ä»»ä½•ä½ æƒ³æ‹çš„å†…å®¹ï¼äº†è§£ä½ çš„æ‹æ‘„æ„å›¾åï¼Œæˆ‘å¯ä»¥æä¾›æ›´ç²¾å‡†çš„æ„å›¾å’Œæ‹æ‘„å»ºè®®ã€‚"""

            self.add_to_message_history("assistant", greeting_message)
            print("å·²å¼€å§‹æ–°çš„æ‹æ‘„ä¼šè¯")
            return greeting_message
        else:
            return "ä¼šè¯å·²ç»å¼€å§‹ï¼Œå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘ä½ æƒ³æ‹æ‘„ä»€ä¹ˆï¼"
    
    def set_photography_intent(self, intent: str):
        """è®¾ç½®ç”¨æˆ·çš„æ‹æ‘„æ„å›¾"""
        self.user_photography_intent = intent
        self.add_to_message_history("user", f"æˆ‘æƒ³æ‹æ‘„ï¼š{intent}")
        
        # AIç¡®è®¤å¹¶æä¾›é¢„æœŸæŒ‡å¯¼
        confirmation_message = f"""å¾ˆå¥½ï¼æˆ‘äº†è§£ä½ æƒ³æ‹æ‘„ **{intent}** ğŸ“¸

ç°åœ¨è¯·æŠŠç›¸æœºå¯¹å‡†ä½ æƒ³æ‹çš„åœºæ™¯ï¼Œæˆ‘ä¼šå®æ—¶åˆ†æç”»é¢å¹¶æä¾›ä¸“ä¸šçš„æ‹æ‘„å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
â€¢ æ„å›¾è°ƒæ•´
â€¢ è§’åº¦ä¼˜åŒ–  
â€¢ ä½ç½®ç§»åŠ¨
â€¢ å…‰çº¿åˆ©ç”¨

å¼€å§‹æ‹æ‘„å§ï¼æˆ‘ä¼šæ ¹æ®ä½ çš„æ‹æ‘„æ„å›¾ç»™å‡ºæœ€åˆé€‚çš„å»ºè®®ã€‚"""

        self.add_to_message_history("assistant", confirmation_message)
        print(f"ç”¨æˆ·æ‹æ‘„æ„å›¾å·²è®¾ç½®: {intent}")
        return confirmation_message
    
    def load_extracted_knowledge(self, knowledge_file: str) -> Dict[str, str]:
        """åŠ è½½é¢„å¤„ç†çš„ç²¾ç®€çŸ¥è¯†åº“"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                knowledge_file,  # å½“å‰ç›®å½•
                os.path.join('..', knowledge_file),  # çˆ¶ç›®å½•
                os.path.join(os.path.dirname(__file__), knowledge_file),  # agentæ–‡ä»¶åŒçº§ç›®å½•
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    print(f"æ‰¾åˆ°çŸ¥è¯†åº“æ–‡ä»¶: {path}")
                    with open(path, 'r', encoding='utf-8') as f:
                        knowledge = json.load(f)
                    return knowledge
            
            print(f"çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•äº†ä»¥ä¸‹è·¯å¾„:")
            for path in possible_paths:
                print(f"   - {path}")
            return {}
        except Exception as e:
            print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
            return {}
    
    def analyze_image(self, image_path):
        """åˆ†æå›¾åƒï¼šç²¾ç¡®æ°´å¹³æ£€æµ‹ + åŸºç¡€ä¿¡æ¯"""
        try:
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                return {'error': 'æ— æ³•è¯»å–å›¾ç‰‡'}
            
            height, width = image.shape[:2]
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # åŸºç¡€ä¿¡æ¯
            brightness = np.mean(gray)
            
            # ğŸ”§ ç²¾ç¡®çš„æ°´å¹³æ£€æµ‹
            level_info = self._detect_horizon_level_precise(gray, width, height)
            
            return {
                'width': int(width),  # ç¡®ä¿æ˜¯Python int
                'height': int(height),  # ç¡®ä¿æ˜¯Python int
                'brightness': float(round(brightness, 1)),  # ç¡®ä¿æ˜¯Python float
                'brightness_level': str(self._categorize_brightness(brightness)),  # ç¡®ä¿æ˜¯Python str
                
                # ç²¾ç¡®çš„æ°´å¹³æ£€æµ‹ç»“æœ
                'is_level': level_info['is_level'],
                'tilt_angle': level_info['tilt_angle'],
                'tilt_direction': level_info['tilt_direction'],
                'level_confidence': level_info['confidence']
            }
            
        except Exception as e:
            return {'error': f'å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}'}
    
    def _detect_horizon_level_precise(self, gray_image, width, height):
        """ç²¾ç¡®çš„æ°´å¹³æ£€æµ‹ï¼ˆOpenCVç®—æ³•ï¼‰"""
        try:
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)
            
            # éœå¤«çº¿å˜æ¢
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=min(width, height)//4)
            
            if lines is None:
                return {'is_level': True, 'tilt_angle': 0, 'tilt_direction': 'level', 'confidence': 0.3}
            
            # æ”¶é›†æ°´å¹³çº¿è§’åº¦
            horizontal_angles = []
            for line in lines:
                rho, theta = line[0]
                angle_deg = math.degrees(theta)
                
                # åªè€ƒè™‘æ¥è¿‘æ°´å¹³çš„çº¿æ¡
                if angle_deg < 30 or angle_deg > 150:
                    if angle_deg > 150:
                        angle_deg = angle_deg - 180
                    horizontal_angles.append(angle_deg)
            
            if not horizontal_angles:
                return {'is_level': True, 'tilt_angle': 0, 'tilt_direction': 'level', 'confidence': 0.3}
            
            # è®¡ç®—å¹³å‡å€¾æ–œè§’åº¦
            avg_angle = np.mean(horizontal_angles)
            tolerance = 2.0
            is_level = abs(avg_angle) <= tolerance
            
            # ç¡®å®šå€¾æ–œæ–¹å‘
            if avg_angle > tolerance:
                direction = 'right_high'  # å³è¾¹é«˜
            elif avg_angle < -tolerance:
                direction = 'left_high'   # å·¦è¾¹é«˜
            else:
                direction = 'level'
            
            confidence = min(len(horizontal_angles) / 10.0, 1.0)
            
            return {
                'is_level': bool(is_level),  # ç¡®ä¿æ˜¯Python bool
                'tilt_angle': float(round(abs(avg_angle), 1)),  # ç¡®ä¿æ˜¯Python float
                'tilt_direction': str(direction),  # ç¡®ä¿æ˜¯Python str
                'confidence': float(round(confidence, 2))  # ç¡®ä¿æ˜¯Python float
            }
            
        except Exception as e:
            return {'is_level': True, 'tilt_angle': 0, 'tilt_direction': 'level', 'confidence': 0.1}
    

    def _categorize_brightness(self, brightness):
        """äº®åº¦åˆ†ç±»"""
        if brightness < 50:
            return "æ˜æš—"
        elif brightness < 120:
            return "é€‚ä¸­"
        else:
            return "æ˜äº®"
    

    
    def get_guidance(self, image_path: str) -> str:
        """è·å–æ‹æ‘„æŒ‡å¯¼ï¼ˆè¿”å›JSONæ ¼å¼ï¼‰"""
        try:
            # åˆ†æå›¾ç‰‡
            analysis = self.analyze_image(image_path)
            
            if 'error' in analysis:
                return json.dumps({
                    "error": f"åˆ†æå¤±è´¥: {analysis['error']}",
                    "suggestions": []
                }, ensure_ascii=False, indent=2)
            
            # ğŸ¯ åŒé‡æ°´å¹³æ£€æµ‹ç­–ç•¥
            opencv_detected_tilt = not analysis.get('is_level', True)
            tilt_angle = analysis.get('tilt_angle', 0)
            tilt_direction = analysis.get('tilt_direction', 'level')
            
            suggestions = []
            
            if opencv_detected_tilt:
                # ç­–ç•¥1: OpenCVæ£€æµ‹åˆ°æ˜æ˜¾å€¾æ–œ - ä¼˜å…ˆçº§æœ€é«˜ï¼Œç›´æ¥ä½¿ç”¨
                print(f"OpenCVæ£€æµ‹åˆ°å€¾æ–œ({tilt_direction}, {tilt_angle}åº¦) - ä¼˜å…ˆé‡‡ç”¨")
                
                # æ·»åŠ æ°´å¹³æ ¡æ­£å»ºè®®
                level_suggestion = self._create_level_correction_suggestion(tilt_direction)
                suggestions.append(level_suggestion)
                
                # å…¶ä»–å»ºè®®ç”±AIç”Ÿæˆï¼ˆä¸æ¶‰åŠæ°´å¹³ï¼‰
                ai_suggestions = self._get_ai_suggestions_json(image_path, analysis)
                suggestions.extend(ai_suggestions[:4])  # æœ€å¤š4æ¡ï¼Œæ€»å…±5æ¡
                
            else:
                # ç­–ç•¥2: OpenCVè®¤ä¸ºæ°´å¹³ - è®©AIäºŒæ¬¡æ£€æŸ¥
                print(f"OpenCVè®¤ä¸ºæ°´å¹³ï¼ŒAIäºŒæ¬¡æ£€æŸ¥ä¸­...")
                ai_level_result = self._ai_check_level_only(image_path, analysis)
                
                if not ai_level_result['is_level']:
                    # AIæ£€æµ‹åˆ°å€¾æ–œ - ç¬¬ä¸€æ¡æ‰‹åŠ¿æ ¡æ­£ + 4æ¡å…¶ä»–å»ºè®®
                    print(f"AIæ£€æµ‹åˆ°å€¾æ–œ({ai_level_result['direction']}) - é‡‡ç”¨AIç»“æœ")
                    
                    # æ·»åŠ æ°´å¹³æ ¡æ­£å»ºè®®
                    level_suggestion = self._create_level_correction_suggestion(ai_level_result['direction'])
                    suggestions.append(level_suggestion)
                    
                    # å…¶ä»–å»ºè®®ç”±AIç”Ÿæˆï¼ˆä¸æ¶‰åŠæ°´å¹³ï¼‰
                    ai_suggestions = self._get_ai_suggestions_json(image_path, analysis)
                    suggestions.extend(ai_suggestions[:4])  # æœ€å¤š4æ¡ï¼Œæ€»å…±5æ¡
                else:
                    # AIç¡®è®¤æ°´å¹³ - 5æ¡ä¸æ¶‰åŠæ°´å¹³çš„å»ºè®®
                    print(f"AIç¡®è®¤ç”»é¢æ°´å¹³")
                    ai_suggestions = self._get_ai_suggestions_json(image_path, analysis)
                    suggestions = ai_suggestions[:5]
            
            # ç¡®ä¿æ¯ä¸ªå»ºè®®éƒ½æœ‰æ­£ç¡®çš„stepç¼–å·
            for i, suggestion in enumerate(suggestions):
                suggestion['step'] = i + 1
            
            # è¿”å›JSONæ ¼å¼ï¼ˆè½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼‰
            result = {
                "suggestions": suggestions[:5],  # ç¡®ä¿æœ€å¤š5æ¡å»ºè®®
                "analysis": {
                    "is_level": bool(analysis.get('is_level', True)),  # ç¡®ä¿æ˜¯Python bool
                    "tilt_angle": float(analysis.get('tilt_angle', 0)),  # ç¡®ä¿æ˜¯Python float
                    "brightness": str(analysis.get('brightness_level', 'N/A'))  # ç¡®ä¿æ˜¯Python str
                }
            }
            
            return json.dumps(result, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({
                "error": f"å¤„ç†å¤±è´¥: {str(e)}",
                "suggestions": []
            }, ensure_ascii=False, indent=2)
    
    def _get_ai_suggestions_excluding_level(self, image_path: str, analysis: Dict) -> List[str]:
        """è·å–AIå»ºè®®ï¼Œä½†æ˜ç¡®æ’é™¤æ°´å¹³ç›¸å…³çš„å»ºè®®"""
        try:
            # å¤„ç†å›¾ç‰‡å¤§å°
            processed_image_path = self.resize_image_if_needed(image_path)
            
            # ç¼–ç å›¾ç‰‡
            image_base64 = self.encode_image_to_base64(processed_image_path)
            
            # åˆ›å»ºpromptï¼ˆæ˜ç¡®æ’é™¤æ°´å¹³é—®é¢˜ï¼‰
            prompt = self._create_non_level_prompt(analysis)
            
            # è°ƒç”¨AIæ¨¡å‹
            ai_response = self.call_minimax_api(prompt, image_base64)
            
            if ai_response:
                # è§£æAIå“åº”ï¼Œæå–å»ºè®®
                lines = ai_response.strip().split('\n')
                suggestions = []
                for line in lines:
                    line = line.strip()
                    if line and any(line.startswith(str(i)+'.') for i in range(1, 6)):
                        # ç§»é™¤ç¼–å·
                        suggestion = line.split('.', 1)[1].strip() if '.' in line else line
                        suggestions.append(suggestion)
                return suggestions
            else:
                return self._get_fallback_non_level_suggestions(analysis)
                
        except Exception as e:
            print(f"è·å–AIå»ºè®®å¤±è´¥: {e}")
            return self._get_fallback_non_level_suggestions(analysis)
    
    def _get_ai_suggestions_with_level_check(self, image_path: str, analysis: Dict) -> List[str]:
        """AIå»ºè®®ï¼ˆåŒ…å«æ°´å¹³äºŒæ¬¡æ£€æŸ¥ï¼‰"""
        try:
            # å¤„ç†å›¾ç‰‡å¤§å°
            processed_image_path = self.resize_image_if_needed(image_path)
            
            # ç¼–ç å›¾ç‰‡
            image_base64 = self.encode_image_to_base64(processed_image_path)
            
            # åˆ›å»ºåŒ…å«æ°´å¹³æ£€æŸ¥çš„prompt
            prompt = self._create_level_check_prompt(analysis)
            
            # è°ƒç”¨AIæ¨¡å‹
            ai_response = self.call_minimax_api(prompt, image_base64)
            
            if ai_response:
                # è§£æAIå“åº”ï¼Œæå–å»ºè®®
                lines = ai_response.strip().split('\n')
                suggestions = []
                for line in lines:
                    line = line.strip()
                    if line and any(line.startswith(str(i)+'.') for i in range(1, 6)):
                        # ç§»é™¤ç¼–å·
                        suggestion = line.split('.', 1)[1].strip() if '.' in line else line
                        suggestions.append(suggestion)
                return suggestions
            else:
                return self._get_fallback_with_level_check(analysis)
                
        except Exception as e:
            print(f"è·å–AIå»ºè®®å¤±è´¥: {e}")
            return self._get_fallback_with_level_check(analysis)
    
    def _create_non_level_prompt(self, analysis: Dict) -> str:
        """åˆ›å»ºä¸æ¶‰åŠæ°´å¹³é—®é¢˜çš„promptï¼ˆæ³¨å…¥æ‘„å½±çŸ¥è¯†ï¼‰"""
        brightness = analysis['brightness_level']
        
        # æ³¨å…¥ç›¸å…³çš„æ‘„å½±çŸ¥è¯†
        knowledge_context = self._get_relevant_knowledge()
        
        # æ·»åŠ ç”¨æˆ·æ‹æ‘„æ„å›¾ä¸Šä¸‹æ–‡
        intent_context = ""
        intent_requirement = ""
        if self.user_photography_intent:
            intent_context = f"""
ç”¨æˆ·æ‹æ‘„æ„å›¾: {self.user_photography_intent}
è¯·æ ¹æ®ç”¨æˆ·æƒ³æ‹æ‘„çš„å†…å®¹ç±»å‹ï¼Œæä¾›é’ˆå¯¹æ€§çš„ä¸“ä¸šå»ºè®®ã€‚è€ƒè™‘è¯¥æ‹æ‘„ä¸»é¢˜çš„ç‰¹æ®Šè¦æ±‚å’Œæœ€ä½³å®è·µã€‚"""
            intent_requirement = f"""

ğŸ¯ CRITICAL: ç”¨æˆ·è¦æ‹æ‘„{self.user_photography_intent}ï¼ä½ å¿…é¡»åŸºäºè¿™ä¸ªå…·ä½“ç›®æ ‡åˆ†æç”»é¢å¹¶æä¾›ä¸“ä¸šå»ºè®®ï¼š

æ‹æ‘„{self.user_photography_intent}çš„ä¸“ä¸šè¦æ±‚ï¼š
"""

            # Add specific requirements based on photography type
            if "äººåƒ" in self.user_photography_intent or "è‚–åƒ" in self.user_photography_intent:
                intent_requirement += """
- äººç‰©è¦å æ®ç”»é¢ä¸»è¦ä½ç½®ï¼ŒèƒŒæ™¯è¦ç®€æ´
- ç›¸æœºé«˜åº¦åº”ä¸çœ¼éƒ¨å¹³é½æˆ–ç•¥ä½ï¼ˆæ˜¾å¾—äº²åˆ‡è‡ªç„¶ï¼‰
- é¿å¼€èƒŒæ™¯ä¸­çš„å¹²æ‰°å…ƒç´ ï¼ˆç”µçº¿æ†ã€åƒåœ¾æ¡¶ç­‰ï¼‰
- å¯»æ‰¾æŸ”å’Œçš„å…‰çº¿ï¼Œé¿å…å¼ºçƒˆé˜´å½±
- å»ºè®®åŠ¨ä½œå¿…é¡»é’ˆå¯¹äººåƒæ„å›¾ä¼˜åŒ–ï¼"""

            elif "é£æ™¯" in self.user_photography_intent or "æ™¯è§‚" in self.user_photography_intent:
                intent_requirement += """
- åœ°å¹³çº¿è¦æ°´å¹³ï¼Œå¤©ç©ºä¸åœ°é¢æ¯”ä¾‹è¦åˆç†
- å¯»æ‰¾å‰æ™¯ã€ä¸­æ™¯ã€èƒŒæ™¯çš„å±‚æ¬¡æ„Ÿ
- åŒ…å«å¼•å¯¼çº¿æ¡æˆ–æœ‰è¶£çš„å‰æ™¯å…ƒç´ 
- è€ƒè™‘é»„é‡‘åˆ†å‰²æ„å›¾åŸåˆ™
- å»ºè®®åŠ¨ä½œå¿…é¡»é’ˆå¯¹é£æ™¯æ„å›¾ä¼˜åŒ–ï¼"""

            elif "ç¾é£Ÿ" in self.user_photography_intent or "é£Ÿç‰©" in self.user_photography_intent:
                intent_requirement += f"""
- é‡‡ç”¨45åº¦ä¿¯æ‹è§’åº¦ï¼Œå±•ç°é£Ÿç‰©çš„ç«‹ä½“æ„Ÿå’Œå±‚æ¬¡
- é¿å…æ‰‹æœºé˜´å½±é®æŒ¡é£Ÿç‰©
- é è¿‘æ‹æ‘„çªå‡ºé£Ÿç‰©è´¨æ„Ÿå’Œç»†èŠ‚
- ç®€åŒ–èƒŒæ™¯ï¼Œè®©é£Ÿç‰©æˆä¸ºå”¯ä¸€ç„¦ç‚¹
- å¯»æ‰¾å‡åŒ€è‡ªç„¶å…‰ï¼Œé¿å…é—ªå…‰ç¯

ğŸ”¥ æ¯ä¸ªactionå¿…é¡»åŒ…å«"é£Ÿç‰©"æˆ–"ç¾é£Ÿ"å­—æ ·ï¼å¼ºåˆ¶æ¨¡æ¿ï¼š
- "è¹²ä¸‹45åº¦ä¿¯æ‹ï¼Œè®©é£Ÿç‰©æ›´æœ‰ç«‹ä½“æ„Ÿ"
- "å¾€[æ–¹å‘]ç§»åŠ¨é¿å¼€é˜´å½±ï¼Œè®©é£Ÿç‰©å…‰çº¿æ›´å¥½"
- "é è¿‘[è·ç¦»]çªå‡ºé£Ÿç‰©çš„[ç‰¹å¾]ç»†èŠ‚"
- "è°ƒæ•´è§’åº¦è®©é£Ÿç‰©å æ®ç”»é¢[æ¯”ä¾‹]"""

            elif "å»ºç­‘" in self.user_photography_intent:
                intent_requirement += """
- å¯»æ‰¾å¯¹ç§°æ„å›¾ï¼Œè®©å»ºç­‘çº¿æ¡å‚ç›´
- åé€€å¯»æ‰¾å®Œæ•´å»ºç­‘è½®å»“ï¼Œé¿å…é€è§†å˜å½¢
- åˆ©ç”¨å¼•å¯¼çº¿æ¡å¢å¼ºå»ºç­‘çš„æ°”åŠ¿
- è€ƒè™‘ä»°æ‹æˆ–ä¿¯æ‹å±•ç°å»ºç­‘ç‰¹è‰²
- å»ºè®®åŠ¨ä½œå¿…é¡»é’ˆå¯¹å»ºç­‘æ‘„å½±ä¼˜åŒ–ï¼"""

            else:
                intent_requirement += f"""
- é’ˆå¯¹{self.user_photography_intent}çš„ç‰¹æ®Šæ‹æ‘„éœ€æ±‚
- è€ƒè™‘è¿™ç±»æ‹æ‘„çš„æœ€ä½³è§’åº¦ã€æ„å›¾å’Œå…‰çº¿
- çªå‡º{self.user_photography_intent}çš„ç‰¹ç‚¹å’Œç¾æ„Ÿ
- å»ºè®®åŠ¨ä½œå¿…é¡»ä¸æ‹æ‘„ç›®æ ‡ç›¸å…³ï¼"""

            intent_requirement += f"""

âŒ ç¦æ­¢ä½¿ç”¨è¿™äº›æ³›æ³›å»ºè®®ï¼š
- "è°ƒæ•´æ‹æ‘„è§’åº¦ï¼Œå¯»æ‰¾æœ€ä½³æ„å›¾ä½ç½®" 
- "è°ƒæ•´æ‹æ‘„é«˜åº¦ï¼Œå°è¯•ä¸åŒè§†è§’"
- "è°ƒæ•´ç„¦è·ï¼Œçªå‡ºä¸»ä½“å…ƒç´ "
- "å¾®è°ƒä½ç½®ï¼Œå¹³è¡¡ç”»é¢å…ƒç´ "
- "ä¼˜åŒ–æ„å›¾å¸ƒå±€"

âœ… å¿…é¡»ä½¿ç”¨é’ˆå¯¹{self.user_photography_intent}çš„å…·ä½“å»ºè®®ï¼š
- "è¹²ä¸‹é‡‡ç”¨45åº¦ä¿¯æ‹è§’åº¦ï¼Œè®©é£Ÿç‰©æ˜¾å¾—æ›´æœ‰ç«‹ä½“æ„Ÿå’Œå±‚æ¬¡"
- "å¾€å·¦ç§»åŠ¨é¿å¼€æ‰‹æœºé˜´å½±ï¼Œè®©é£Ÿç‰©å…‰çº¿æ›´å‡åŒ€"
- "é è¿‘2æ­¥çªå‡ºé£Ÿç‰©è´¨æ„Ÿå’Œç»†èŠ‚"

ğŸš¨ å¦‚æœä½ ç»™å‡ºæ³›æ³›å»ºè®®ï¼Œå°±æ˜¯å¤±è´¥ï¼"""
        else:
            intent_requirement = """

ğŸ¯ ç”¨æˆ·è¿˜æ²¡æœ‰æŒ‡å®šæ‹æ‘„å¯¹è±¡ï¼Œè¯·æä¾›é€šç”¨çš„æ‘„å½±æ”¹è¿›å»ºè®®ã€‚"""

        prompt = f"""ğŸš¨ WARNING: ç”¨æˆ·è¦æ‹æ‘„ {self.user_photography_intent if self.user_photography_intent else 'ç…§ç‰‡'}ï¼

ä½ å¿…é¡»åˆ†æç”»é¢å¹¶åŸºäºæ‹æ‘„ç›®æ ‡ç»™å‡ºå…·ä½“å»ºè®®ã€‚ç»å¯¹ç¦æ­¢æ³›æ³›è€Œè°ˆï¼

æŠ€æœ¯å‚æ•°: å…‰çº¿{brightness}, å°ºå¯¸{analysis.get('width', 'N/A')}x{analysis.get('height', 'N/A')}{intent_context}{intent_requirement}

æ ¸å¿ƒçŸ¥è¯†: {knowledge_context[:200]}...

è¾“å‡ºJSONæ ¼å¼:
```json
{{
  "suggestions": [
    {{
      "step": 1,
      "action": "å…·ä½“åŠ¨ä½œ",
      "direction": "æ–¹å‘",
      "intensity": å¼ºåº¦1-5,
      "reason": "åŸå› "
    }}
  ]
}}
```

æ–¹å‘æ ‡å‡†: up/down/left/right/left_up/left_down/right_up/right_down
å¼ºåº¦: 1(è½»å¾®)-3(å¤§å¹…)

```json
{{
  "suggestions": [
    {{
      "step": 1,
      "action": "å…·ä½“çš„åŠ¨ä½œæè¿°",
      "direction": "ç§»åŠ¨æ–¹å‘",
      "intensity": å¼ºåº¦ç­‰çº§æ•°å­—,
      "reason": "é€‰æ‹©è¿™ä¸ªæ–¹å‘çš„ç®€å•åŸå› "
    }},
    {{
      "step": 2,
      "action": "å…·ä½“çš„åŠ¨ä½œæè¿°", 
      "direction": "ç§»åŠ¨æ–¹å‘",
      "intensity": å¼ºåº¦ç­‰çº§æ•°å­—,
      "reason": "é€‰æ‹©è¿™ä¸ªæ–¹å‘çš„ç®€å•åŸå› "
    }},
    {{
      "step": 3,
      "action": "å…·ä½“çš„åŠ¨ä½œæè¿°",
      "direction": "ç§»åŠ¨æ–¹å‘",
      "intensity": å¼ºåº¦ç­‰çº§æ•°å­—,
      "reason": "é€‰æ‹©è¿™ä¸ªæ–¹å‘çš„ç®€å•åŸå› "
    }}
  ]
}}
```

=== æ–¹å‘æ ‡å‡†ï¼ˆé‡è¦ï¼šç»Ÿä¸€åæ ‡ç³»ï¼‰ ===
âš ï¸ æ–¹å‘å®šä¹‰ï¼šä»¥æ‹ç…§è€…çš„è§†è§’ä¸ºå‡†ï¼Œé¢å¯¹æ‹æ‘„åœºæ™¯æ—¶ï¼š
- "left" = æ‹ç…§è€…çš„å·¦æ‰‹è¾¹ï¼ˆç”»é¢å·¦ä¾§ï¼‰
- "right" = æ‹ç…§è€…çš„å³æ‰‹è¾¹ï¼ˆç”»é¢å³ä¾§ï¼‰  
- "up" = å‘ä¸Šç§»åŠ¨/ç«™é«˜/ä¸¾é«˜æ‰‹æœº
- "down" = å‘ä¸‹ç§»åŠ¨/è¹²ä¸‹/é™ä½æ‰‹æœº

directionå­—æ®µå¿…é¡»æ˜¯ä»¥ä¸‹8ä¸ªæ ‡å‡†æ–¹å‘ä¹‹ä¸€ï¼š
- "up" (å‘ä¸Š/ç«™é«˜/ä¸¾é«˜æ‰‹æœº)
- "down" (å‘ä¸‹/è¹²ä¸‹/é™ä½æ‰‹æœº)  
- "left" (å¾€æ‹ç…§è€…å·¦æ‰‹è¾¹ç§»åŠ¨)
- "right" (å¾€æ‹ç…§è€…å³æ‰‹è¾¹ç§»åŠ¨)
- "left_up" (å¾€å·¦ä¸Šæ–¹ç§»åŠ¨)
- "left_down" (å¾€å·¦ä¸‹æ–¹ç§»åŠ¨)
- "right_up" (å¾€å³ä¸Šæ–¹ç§»åŠ¨)
- "right_down" (å¾€å³ä¸‹æ–¹ç§»åŠ¨)

ğŸ¯ åˆ¤æ–­æ–¹å‘æ—¶è¯·åŸºäºç”»é¢å†…å®¹ï¼š
- å¦‚æœæƒ³æ‹åˆ°ç”»é¢å·¦ä¾§æ›´å¤šå†…å®¹ â†’ "left"
- å¦‚æœæƒ³æ‹åˆ°ç”»é¢å³ä¾§æ›´å¤šå†…å®¹ â†’ "right"
- é¿å…ä¸»ä½“è¢«å·¦è¾¹ç‰©ä½“é®æŒ¡ â†’ "right" 
- é¿å…ä¸»ä½“è¢«å³è¾¹ç‰©ä½“é®æŒ¡ â†’ "left"

=== å¼ºåº¦ç­‰çº§ ===
intensityå­—æ®µå¿…é¡»æ˜¯1-5çš„æ•´æ•°ï¼Œè¡¨ç¤ºåŠ¨ä½œå¹…åº¦ï¼š
- 1: è½»å¾®è°ƒæ•´ (ç¨å¾®ã€ä¸€ç‚¹ç‚¹)
- 2: å°å¹…è°ƒæ•´ (ä¸€ç‚¹ã€1æ­¥)
- 3: ä¸­ç­‰è°ƒæ•´ (2-3æ­¥ã€é€‚ä¸­è·ç¦»)
- 4: è¾ƒå¤§è°ƒæ•´ (4-5æ­¥ã€è¾ƒå¤§å¹…åº¦)
- 5: å¤§å¹…è°ƒæ•´ (å¾ˆå¤šæ­¥ã€å¤§å¹…åº¦ç§»åŠ¨)

=== å†…å®¹è¦æ±‚ ===
- ä¸è¦æ¶‰åŠç”»é¢æ°´å¹³é—®é¢˜ï¼ˆå…¶ä»–ç³»ç»Ÿä¼šå¤„ç†ï¼‰
- åŸºäºä¸“ä¸šæ‘„å½±çŸ¥è¯†ï¼Œä½†ç”¨æœ€ç®€å•çš„è¯è¡¨è¾¾
- actionè¦å…·ä½“æè¿°ï¼š"å¾€å·¦èµ°2æ­¥æ‰¾åˆ°æ›´å¥½è§’åº¦"ã€"è¹²ä¸‹æ¥ä»ä½è§’åº¦æ‹æ‘„"
- ç”¨å¤§ç™½è¯ï¼š"æ”¾å¤§"/"ç¼©å°"ï¼ˆä¸è¯´ç„¦è·ï¼‰
- æ¯ä¸ªactionè¦å®ç”¨ä¸”æ˜“æ‰§è¡Œ
- ğŸš¨ CRITICAL: æ¯ä¸ªå»ºè®®å¿…é¡»é’ˆå¯¹ç”¨æˆ·çš„æ‹æ‘„ç›®æ ‡ï¼Œä¸èƒ½æ˜¯é€šç”¨å»ºè®®ï¼
- ğŸš¨ æ ¹æ®æ‹æ‘„å¯¹è±¡æä¾›ä¸“ä¸šçš„æ„å›¾ã€è§’åº¦ã€å…‰çº¿å»ºè®®ï¼

âš ï¸ æ–¹å‘åˆ¤æ–­å…³é”®åŸåˆ™ï¼š
- ä»”ç»†è§‚å¯Ÿç”»é¢å†…å®¹å’Œæ„å›¾éœ€æ±‚
- åŸºäº"æ‹ç…§è€…è§†è§’"ç»™å‡ºç§»åŠ¨æ–¹å‘
- å¦‚æœç”»é¢å³ä¾§æœ‰æ›´å¥½çš„æ™¯è‰²ï¼Œå»ºè®®"right"ï¼ˆå¾€å³ç§»åŠ¨ï¼‰
- å¦‚æœç”»é¢å·¦ä¾§æœ‰æ›´å¥½çš„æ™¯è‰²ï¼Œå»ºè®®"left"ï¼ˆå¾€å·¦ç§»åŠ¨ï¼‰
- å¦‚æœä¸»ä½“è¢«å·¦ä¾§ç‰©ä½“é®æŒ¡ï¼Œå»ºè®®"right"ï¼ˆå¾€å³ç§»åŠ¨é¿å¼€é®æŒ¡ï¼‰
- æ–¹å‘è¦ä¸å®é™…æ”¹å–„ç”»é¢çš„é€»è¾‘ä¸€è‡´
- åœ¨reasonå­—æ®µä¸­ç®€å•è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ–¹å‘ï¼ˆå¦‚ï¼š"é¿å¼€é®æŒ¡"ã€"åŒ…å«æ›´å¤šæ™¯è‰²"ã€"æ”¹å–„æ„å›¾"ï¼‰

åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        return prompt
    
    def _get_relevant_knowledge(self) -> str:
        """è·å–ç›¸å…³çš„æ‘„å½±çŸ¥è¯†ç‚¹"""
        if not self.extracted_knowledge:
            return "æš‚æ— ä¸“ä¸šçŸ¥è¯†åº“æ”¯æŒ"
        
        # é€‰æ‹©ä¸€äº›é€šç”¨çš„ã€æœ‰æŒ‡å¯¼ä»·å€¼çš„çŸ¥è¯†ç‚¹
        relevant_keys = [
            key for key in self.extracted_knowledge.keys() 
            if any(keyword in key for keyword in [
                'æ„å›¾', 'å…‰çº¿', 'è§’åº¦', 'äººåƒ', 'é£æ™¯', 'è‰²å½©', 'æŠ€å·§', 
                'æ‹æ‘„', 'æ‘„å½±', 'è§†è§’', 'èƒŒæ™¯', 'å‰æ™¯', 'å¯¹æ¯”', 'å±‚æ¬¡'
            ])
        ]
        
        # éšæœºé€‰æ‹©3-5ä¸ªç›¸å…³çŸ¥è¯†ç‚¹
        import random
        selected_keys = random.sample(relevant_keys, min(5, len(relevant_keys))) if relevant_keys else list(self.extracted_knowledge.keys())[:5]
        
        knowledge_text = ""
        for key in selected_keys:
            knowledge_text += f"â€¢ {self.extracted_knowledge[key]}\n"
        
        return knowledge_text.strip() if knowledge_text else "ä½¿ç”¨åŸºç¡€æ‘„å½±åŸç†æŒ‡å¯¼"
    
    def _ai_check_level_only(self, image_path: str, analysis: Dict) -> Dict:
        """AIä¸“é—¨æ£€æŸ¥æ°´å¹³çŠ¶æ€ï¼Œåªè¿”å›True/Falseå’Œæ–¹å‘"""
        try:
            prompt = self._create_level_check_only_prompt(analysis)
            
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            base64_image = base64.b64encode(image_data).decode('utf-8')
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                            }
                        ]
                    }
                ],
                max_tokens=10,  # åªéœ€è¦ä¸€ä¸ªè¯ï¼Œå¤§å¹…å‡å°‘tokenæ¶ˆè€—
                temperature=0.1  # é™ä½éšæœºæ€§ï¼Œç¡®ä¿å›ç­”ç¨³å®šä¸€è‡´
            )
            
            result = response.choices[0].message.content.strip().lower()
            print(f"AIæ°´å¹³æ£€æµ‹åŸå§‹å›ç­”: '{result}'")
            
            # ä¼˜åŒ–çš„è§£æé€»è¾‘ - æ›´ç²¾ç¡®çš„å…³é”®è¯åŒ¹é…
            if any(keyword in result for keyword in ['æ°´å¹³', 'å¹³ç¨³', 'å¹³', 'level', 'æ­£å¸¸', 'ä¸å€¾æ–œ']):
                print("AIåˆ¤æ–­: ç”»é¢æ°´å¹³")
                return {'is_level': True, 'direction': 'level'}
            elif any(keyword in result for keyword in ['å·¦è¾¹é«˜', 'å·¦é«˜', 'å·¦å€¾', 'å·¦ä¾§é«˜', 'left_high', 'å·¦è¾¹']):
                print("AIåˆ¤æ–­: å·¦è¾¹é«˜ï¼Œå»ºè®®å³æ‰‹æŠ¬èµ·")
                return {'is_level': False, 'direction': 'left_high'}
            elif any(keyword in result for keyword in ['å³è¾¹é«˜', 'å³é«˜', 'å³å€¾', 'å³ä¾§é«˜', 'right_high', 'å³è¾¹']):
                print("AIåˆ¤æ–­: å³è¾¹é«˜ï¼Œå»ºè®®å·¦æ‰‹æŠ¬èµ·")
                return {'is_level': False, 'direction': 'right_high'}
            else:
                print(f"âš ï¸ AIå›ç­”æ ¼å¼å¼‚å¸¸ï¼Œé»˜è®¤åˆ¤æ–­ä¸ºè½»å¾®å€¾æ–œ: '{result}'")
                # é»˜è®¤è®¤ä¸ºæœ‰è½»å¾®å€¾æ–œï¼Œäº¤ç”±ç”¨æˆ·åˆ¤æ–­
                return {'is_level': False, 'direction': 'unknown'}
                
        except Exception as e:
            print(f"AIæ°´å¹³æ£€æµ‹å¤±è´¥: {e}")
            return {'is_level': True, 'direction': 'level'}  # é»˜è®¤è®¤ä¸ºæ°´å¹³
    
    def _create_level_check_only_prompt(self, analysis: Dict) -> str:
        """åˆ›å»ºä¸“é—¨ç”¨äºæ°´å¹³æ£€æŸ¥çš„promptï¼ˆåŸºäºä¸“ä¸šæ‘„å½±çŸ¥è¯†ï¼‰"""
        
        # è·å–æ°´å¹³æ£€æµ‹ç›¸å…³çš„ä¸“ä¸šçŸ¥è¯†
        level_knowledge = self._get_level_detection_knowledge()
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æ‘„å½±æŠ€æœ¯åˆ†æå¸ˆï¼Œéœ€è¦åŸºäºä¸“ä¸šçŸ¥è¯†å¿«é€Ÿå‡†ç¡®åˆ¤æ–­ç…§ç‰‡æ°´å¹³çŠ¶æ€ã€‚

=== ä¸“ä¸šçŸ¥è¯†åŸºç¡€ ===
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‘„å½±å¸ˆï¼Œä½ è¦é€šè¿‡ç…§ç‰‡çš„å…¨å±€æ¥åˆ¤æ–­è¿™ä¸ªå›¾ç‰‡çš„æ°´å¹³ä¸å¦ï¼Œå¯ä»¥å‚è€ƒä¸€äº›çŸ¥è¯†ï¼š{level_knowledge}

=== æ°´å¹³æ£€æµ‹ä¸“ä¸šæ–¹æ³• ===
1. **å‚è€ƒçº¿æ³•**ï¼šæƒ³è±¡ç”»é¢ä¸Šæœ‰ä¹å®«æ ¼è¾…åŠ©çº¿ï¼Œæ£€æŸ¥æ°´å¹³å‚è€ƒçº¿æ˜¯å¦ä¸ç”»é¢è¾¹ç¼˜å¹³è¡Œ
2. **å¯¹ç§°æ€§æ£€æŸ¥**ï¼šè§‚å¯Ÿç”»é¢å·¦å³ä¸¤ä¾§çš„è§†è§‰é‡é‡æ˜¯å¦å¹³è¡¡ï¼Œå€¾æ–œä¼šç ´åå¯¹ç§°æ„Ÿ
3. **è¾¹ç¼˜å¯¹æ¯”æ³•**ï¼šé‡ç‚¹å…³æ³¨ç”»é¢é¡¶éƒ¨å’Œåº•éƒ¨è¾¹ç¼˜çº¿ï¼Œå¿½ç•¥ç‰©ä½“æœ¬èº«çš„å€¾æ–œ
4. **è§†è§‰é‡å¿ƒæ³•**ï¼šæ£€æŸ¥ç”»é¢çš„è§†è§‰é‡å¿ƒæ˜¯å¦ç¨³å®šï¼Œä¸å‘æŸä¸€ä¾§å€¾æ–œ

=== å½“å‰å›¾ç‰‡æ•°æ® ===
- å›¾ç‰‡å°ºå¯¸: {analysis.get('width', 'N/A')} x {analysis.get('height', 'N/A')}

=== åˆ¤æ–­ä»»åŠ¡ ===
è¿ç”¨ä¸Šè¿°ä¸“ä¸šæ–¹æ³•ï¼Œé‡ç‚¹æ£€æŸ¥ï¼š
â€¢ ç”»é¢æ•´ä½“çš„æ°´å¹³åŸºå‡†çº¿ï¼ˆä¸æ˜¯ç‰©ä½“ï¼‰
â€¢ ç”»é¢çš„è§†è§‰å¹³è¡¡æ„Ÿå’Œç¨³å®šæ€§
â€¢ å·¦å³ä¸¤ä¾§æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„é«˜åº¦å·®å¼‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼ˆåªèƒ½æ˜¯è¿™ä¸‰ä¸ªè¯ä¹‹ä¸€ï¼‰ï¼š
â€¢ "æ°´å¹³" - ç”»é¢æ•´ä½“å¹³ç¨³ï¼Œæ— æ˜æ˜¾å€¾æ–œ
â€¢ "å·¦è¾¹é«˜" - ç”»é¢å·¦ä¾§ç›¸å¯¹è¾ƒé«˜ï¼Œéœ€è¦å³æ‰‹æŠ¬èµ·æ ¡æ­£  
â€¢ "å³è¾¹é«˜" - ç”»é¢å³ä¾§ç›¸å¯¹è¾ƒé«˜ï¼Œéœ€è¦å·¦æ‰‹æŠ¬èµ·æ ¡æ­£

åªå›ç­”ä¸€ä¸ªè¯ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚"""
        return prompt
    
    def _get_level_detection_knowledge(self) -> str:
        """è·å–æ°´å¹³æ£€æµ‹ç›¸å…³çš„ä¸“ä¸šçŸ¥è¯†"""
        if not self.extracted_knowledge:
            return "åŸºäºæ‘„å½±æ„å›¾å’Œè§†è§‰å¹³è¡¡åŸç†"
        
        # é€‰æ‹©ä¸æ°´å¹³ã€æ„å›¾ã€è§†è§‰å¹³è¡¡ç›¸å…³çš„çŸ¥è¯†ç‚¹
        relevant_keys = [
            key for key in self.extracted_knowledge.keys() 
            if any(keyword in key for keyword in [
                'æ°´å¹³', 'æ„å›¾', 'ç¨³å®š', 'å¹³è¡¡', 'å¯¹ç§°', 'è¾…åŠ©çº¿', 'å‚è€ƒçº¿',
                'è§†è§‰', 'å€¾æ–œ', 'æ¨ªå¹³ç«–ç›´', 'è§†è§’', 'é‡å¿ƒ'
            ])
        ]
        
        # ä¼˜å…ˆé€‰æ‹©æœ€ç›¸å…³çš„çŸ¥è¯†ç‚¹
        priority_keywords = ['æ°´å¹³', 'è¾…åŠ©çº¿', 'å¯¹ç§°', 'ç¨³å®š', 'æ„å›¾']
        selected_keys = []
        
        for keyword in priority_keywords:
            for key in relevant_keys:
                if keyword in key and key not in selected_keys:
                    selected_keys.append(key)
                    if len(selected_keys) >= 4:  # é™åˆ¶æ•°é‡ä¿æŒpromptç®€æ´
                        break
            if len(selected_keys) >= 4:
                break
        
        # å¦‚æœè¿˜ä¸å¤Ÿï¼Œæ·»åŠ å…¶ä»–ç›¸å…³çŸ¥è¯†
        if len(selected_keys) < 4:
            for key in relevant_keys:
                if key not in selected_keys:
                    selected_keys.append(key)
                    if len(selected_keys) >= 4:
                        break
        
        knowledge_text = ""
        for key in selected_keys:
            knowledge_text += f"â€¢ {self.extracted_knowledge[key]}\n"
        
        return knowledge_text.strip() if knowledge_text else "â€¢ æ°´å¹³æ‹æ‘„é¿å…æ­ªæ–œï¼Œæå‡ç”»é¢ç¨³å®šæ€§\nâ€¢ å‚è€ƒçº¿å¸®åŠ©åˆ¤æ–­ç”»é¢æ˜¯å¦æ¨ªå¹³ç«–ç›´\nâ€¢ å¯¹ç§°æ„å›¾ä¸ä¼šå‡ºç°å·¦å³å€¾æ–œé—®é¢˜\nâ€¢ è§†è§‰å¹³è¡¡æ„Ÿæ˜¯åˆ¤æ–­æ°´å¹³çš„é‡è¦ä¾æ®"

    def _create_level_check_prompt(self, analysis: Dict) -> str:
        """åˆ›å»ºåŒ…å«æ°´å¹³äºŒæ¬¡æ£€æŸ¥çš„prompt"""
        brightness = analysis['brightness_level']

        prompt = f"""ä½ æ˜¯æ‰‹æœºæ‹ç…§æ•™ç»ƒï¼Œç”¨æœ€ç®€å•çš„è¯æ•™ç”¨æˆ·æ‹ç…§ã€‚

å½“å‰å…‰çº¿: {brightness}

ä»ªå™¨æ˜¾ç¤ºç…§ç‰‡åŸºæœ¬æ˜¯å¹³çš„ï¼Œä½†è¯·ä½ å†ä»”ç»†çœ‹çœ‹ç…§ç‰‡ï¼Œæ£€æŸ¥æ˜¯ä¸æ˜¯çœŸçš„å¹³ã€‚

è¯·ç»™å‡º5ä¸ªç®€å•æ˜“æ‡‚çš„æ‹ç…§å»ºè®®ï¼š

1. [ç®€å•åŠ¨ä½œ]
2. [ç®€å•åŠ¨ä½œ]
3. [ç®€å•åŠ¨ä½œ]
4. [ç®€å•åŠ¨ä½œ]
5. [ç®€å•åŠ¨ä½œ]

è¦æ±‚ï¼š
- å…ˆçœ‹ç…§ç‰‡æ˜¯ä¸æ˜¯çœŸçš„å¹³ï¼Œå¦‚æœæ­ªäº†ï¼š
  * å¦‚æœå·¦è¾¹é«˜ï¼Œè¯´"å³æ‰‹æŠ¬èµ·æ¥"
  * å¦‚æœå³è¾¹é«˜ï¼Œè¯´"å·¦æ‰‹æŠ¬èµ·æ¥"
- ç”¨æœ€ç®€å•çš„è¯ï¼Œåƒæ•™å°æœ‹å‹ä¸€æ ·
- è¯´å…·ä½“æ–¹å‘ï¼š"å¾€å·¦èµ°2æ­¥"ã€"å¾€å³èµ°1æ­¥"ã€"è¹²ä¸‹æ¥"ã€"ç«™é«˜ä¸€ç‚¹"
- ä¸è¦è¯´"ç„¦è·"ï¼Œè¦è¯´"æ”¾å¤§"æˆ–"ç¼©å°"
- ä¸è¦è¯´ä¸“ä¸šè¯æ±‡ï¼Œè¦è¯´å¤§ç™½è¯

åªè¿”å›5æ¡ç®€å•æŒ‡ä»¤ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        return prompt
    
    def _get_fallback_non_level_suggestions(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆä¸æ¶‰åŠæ°´å¹³çš„åå¤‡å»ºè®®"""
        suggestions = [
            "å¾€å·¦è¾¹æˆ–å¾€å³è¾¹èµ°2æ­¥",
            "è¹²ä¸‹æ¥ä¸€ç‚¹ï¼Œæˆ–è€…ç«™é«˜ä¸€ç‚¹",
            "æ‰‹æœºç¨å¾®å¾€ä¸ŠæŠ¬ï¼Œæˆ–è€…å¾€ä¸‹å‹ä¸€ç‚¹",
            "æ‹¿ç¨³æ‰‹æœºï¼Œæ·±å‘¼å¸å†æ‹"
        ]
        
        # æ ¹æ®å…‰çº¿è°ƒæ•´
        if analysis['brightness_level'] == 'æ˜æš—':
            suggestions[3] = "èµ°åˆ°äº®ä¸€ç‚¹çš„åœ°æ–¹"
        
        return suggestions
    
    def _get_fallback_with_level_check(self, analysis: Dict) -> List[str]:
        """ç”ŸæˆåŒ…å«æ°´å¹³æ£€æŸ¥çš„åå¤‡å»ºè®®"""
        suggestions = [
            "çœ‹çœ‹å±å¹•ï¼Œç…§ç‰‡æ˜¯ä¸æ˜¯æ‹æ­ªäº†",
            "å¾€å·¦è¾¹æˆ–å¾€å³è¾¹èµ°2æ­¥",
            "è¹²ä¸‹æ¥ä¸€ç‚¹ï¼Œæˆ–è€…ç«™é«˜ä¸€ç‚¹",
            "æ‹¿ç¨³æ‰‹æœºï¼Œæ·±å‘¼å¸å†æ‹",
            "çœ‹çœ‹å…‰çº¿å¥½ä¸å¥½ï¼Œèµ°åˆ°äº®ä¸€ç‚¹çš„åœ°æ–¹"
        ]
        
        # æ ¹æ®å…‰çº¿è°ƒæ•´
        if analysis['brightness_level'] == 'æ˜æš—':
            suggestions[4] = "å¤ªæš—äº†ï¼Œèµ°åˆ°äº®ä¸€ç‚¹çš„åœ°æ–¹"
        
        return suggestions
    
    def resize_image_if_needed(self, image_path: str) -> str:
        """å¦‚æœéœ€è¦ï¼Œè°ƒæ•´å›¾ç‰‡å¤§å°"""
        try:
            with Image.open(image_path) as img:
                # æ›´æ¿€è¿›çš„å‹ç¼©ç­–ç•¥
                max_size = (1280, 720)  # é™ä½åˆ†è¾¨ç‡ä»¥åŠ å¿«ä¼ è¾“
                if img.size[0] > max_size[0] or img.size[1] > max_size[1]:
                    img.thumbnail(max_size, Image.Resampling.LANCZOS)
                    resized_path = f"temp_resized_{os.path.basename(image_path)}"
                    img.save(resized_path, quality=75, optimize=True)  # é™ä½è´¨é‡ä»¥å‡å°æ–‡ä»¶å¤§å°
                    return resized_path
                return image_path
        except Exception:
            return image_path
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        try:
            with open(image_path, 'rb') as f:
                return base64.b64encode(f.read()).decode('utf-8')
        except Exception as e:
            raise Exception(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {e}")
    
    def call_minimax_api(self, prompt: str, image_base64: str) -> str:
        """è°ƒç”¨Minimax API"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                            }
                        ]
                    }
                ],
                max_tokens=Config.MAX_TOKENS,
                temperature=Config.TEMPERATURE,
                extra_headers={
                    "HTTP-Referer": Config.SITE_URL,
                    "X-Title": Config.SITE_NAME,
                }
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def _create_level_correction_suggestion(self, tilt_direction: str) -> dict:
        """åˆ›å»ºæ°´å¹³æ ¡æ­£å»ºè®®"""
        if tilt_direction == 'right_high':
            return {
                "step": 1,
                "action": "å·¦æ‰‹æŠ¬é«˜ä¸€ç‚¹ï¼ŒæŠŠæ‰‹æœºæ‹¿å¹³ï¼Œç…§ç‰‡æ‹æ­ªäº†",
                "direction": "left_up",
                "intensity": 2,
                "reason": "æ ¡æ­£å³è¾¹é«˜çš„å€¾æ–œ"
            }
        elif tilt_direction == 'left_high':
            return {
                "step": 1,
                "action": "å³æ‰‹æŠ¬é«˜ä¸€ç‚¹ï¼ŒæŠŠæ‰‹æœºæ‹¿å¹³ï¼Œç…§ç‰‡æ‹æ­ªäº†", 
                "direction": "right_up",
                "intensity": 2,
                "reason": "æ ¡æ­£å·¦è¾¹é«˜çš„å€¾æ–œ"
            }
        else:
            return {
                "step": 1,
                "action": "è°ƒæ•´æ‰‹æœºè§’åº¦ï¼Œè®©ç”»é¢ä¿æŒæ°´å¹³",
                "direction": "up",
                "intensity": 2,
                "reason": "ä¿æŒç”»é¢æ°´å¹³"
            }
    
    def _get_ai_suggestions_json(self, image_path: str, analysis: dict) -> list:
        """è·å–AIå»ºè®®å¹¶è§£æä¸ºJSONæ ¼å¼"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self.get_cache_key(image_path, analysis)
            cached_result = self.get_cached_result(cache_key)
            if cached_result:
                return cached_result
            
            prompt = self._create_non_level_prompt(analysis)
            
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # æ„å»ºåŒ…å«å†å²è®°å½•çš„æ¶ˆæ¯æ•°ç»„
            messages = self.message_history.copy()  # å¤åˆ¶å†å²æ¶ˆæ¯
            
            # ğŸš¨ Add explicit system message for context
            if self.user_photography_intent:
                system_message = {
                    "role": "system", 
                    "content": f"ä½ æ˜¯ä¸“ä¸šæ‘„å½±å¸ˆã€‚ç”¨æˆ·æ­£åœ¨æ‹æ‘„{self.user_photography_intent}ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”»é¢å¹¶ç»™å‡º4ä¸ªå…·ä½“çš„ã€é’ˆå¯¹{self.user_photography_intent}çš„ä¸“ä¸šå»ºè®®ã€‚ç»å¯¹ç¦æ­¢ç»™å‡ºé€šç”¨å»ºè®®ã€‚æ¯ä¸ªå»ºè®®å¿…é¡»æ˜ç¡®è¯´æ˜ä¸ºä»€ä¹ˆè¿™ä¸ªåŠ¨ä½œå¯¹æ‹æ‘„{self.user_photography_intent}æœ‰å¸®åŠ©ã€‚"
                }
                messages.append(system_message)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            current_message = {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                    }
                ]
            }
            messages.append(current_message)
            
            print(f"ä½¿ç”¨æ¶ˆæ¯å†å²: {len(self.message_history)} æ¡å†å²æ¶ˆæ¯ + 1 æ¡æ–°æ¶ˆæ¯")
            
            # ğŸ› DEBUG: Print full prompt being sent to LLM
            print("=" * 80)
            print("ğŸ¤– FULL PROMPT SENT TO LLM:")
            print("=" * 80)
            print(prompt)
            print("=" * 80)
            if self.user_photography_intent:
                print(f"ğŸ“¸ USER PHOTOGRAPHY INTENT: {self.user_photography_intent}")
                print("=" * 80)
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=350,  # å‡å°‘tokenæ•°é‡
                temperature=0.7,  # æé«˜åˆ›é€ æ€§
                timeout=10  # å‡å°‘è¶…æ—¶æ—¶é—´
            )
            
            response_text = response.choices[0].message.content.strip()
            print(f"ğŸ¤– AIåŸå§‹å“åº”: {response_text[:200]}...")
            
            # ğŸ› DEBUG: Print full LLM response
            print("=" * 80)
            print("ğŸ¤– FULL LLM RESPONSE:")
            print("=" * 80)
            print(response_text)
            print("=" * 80)
            
            # ğŸ› DEBUG: Check if user intent is referenced in response
            if self.user_photography_intent and response_text:
                intent_mentioned = self.user_photography_intent in response_text
                print(f"ğŸ¯ USER INTENT REFERENCED IN RESPONSE: {intent_mentioned}")
                if not intent_mentioned:
                    print(f"âš ï¸  WARNING: User intent '{self.user_photography_intent}' NOT found in LLM response!")
                print("=" * 80)
            
            # å°è¯•è§£æJSON
            try:
                # æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«```json```æ ‡è®°ï¼‰
                json_text = self._extract_json_from_response(response_text)
                ai_data = json.loads(json_text)
                
                if 'suggestions' in ai_data and isinstance(ai_data['suggestions'], list):
                    # éªŒè¯å’Œæ ‡å‡†åŒ–æ–¹å‘å’Œå¼ºåº¦
                    validated_suggestions = []
                    for suggestion in ai_data['suggestions']:
                        if isinstance(suggestion, dict) and 'action' in suggestion and 'direction' in suggestion:
                            validated_direction = self._validate_direction(suggestion['direction'])
                            validated_intensity = self._validate_intensity(suggestion.get('intensity', 3))
                            validated_suggestions.append({
                                "step": suggestion.get('step', len(validated_suggestions) + 1),
                                "action": suggestion['action'],
                                "direction": validated_direction,
                                "intensity": validated_intensity,
                                "reason": suggestion.get('reason', 'æ”¹å–„ç”»é¢æ•ˆæœ')
                            })
                    
                    # ğŸ› DEBUG: Validate each suggestion references user intent
                    if self.user_photography_intent:
                        print("=" * 80)
                        print("ğŸ” VALIDATING SUGGESTIONS REFERENCE USER INTENT:")
                        print("=" * 80)
                        for i, suggestion in enumerate(validated_suggestions, 1):
                            action_has_intent = self.user_photography_intent in suggestion.get('action', '')
                            reason_has_intent = self.user_photography_intent in suggestion.get('reason', '')
                            has_intent = action_has_intent or reason_has_intent
                            
                            print(f"å»ºè®® {i}:")
                            print(f"  Action: {suggestion.get('action', 'N/A')}")
                            print(f"  Reason: {suggestion.get('reason', 'N/A')}")
                            print(f"  ğŸ¯ References '{self.user_photography_intent}': {has_intent}")
                            if not has_intent:
                                print(f"  âš ï¸  WARNING: Suggestion {i} does NOT reference user intent!")
                            print()
                        print("=" * 80)
                    
                    # æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•
                    self.add_to_message_history("user", prompt, base64_image)
                    self.add_to_message_history("assistant", response_text)
                    
                    # ç¼“å­˜ç»“æœ
                    self.set_cached_result(cache_key, validated_suggestions)
                    return validated_suggestions
                
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                print(f"åŸå§‹å“åº”: {response_text}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯AIæ‹’ç»å“åº”
                if "sorry" in response_text.lower() or "can't help" in response_text.lower():
                    print("ğŸ¤– AIæ‹’ç»äº†è¯·æ±‚ï¼Œä½¿ç”¨é»˜è®¤å»ºè®®")
                    fallback_result = self._get_fallback_suggestions()
                else:
                    # é™çº§å¤„ç†ï¼šå°è¯•ä»æ–‡æœ¬ä¸­æå–å»ºè®®
                    fallback_result = self._parse_text_to_suggestions(response_text)
                
                # æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•ï¼ˆå³ä½¿è§£æå¤±è´¥ï¼‰
                self.add_to_message_history("user", prompt, base64_image)
                self.add_to_message_history("assistant", response_text)
                
                self.set_cached_result(cache_key, fallback_result)
                return fallback_result
                
        except Exception as e:
            print(f"âŒ AIå»ºè®®è·å–å¤±è´¥: {e}")
            
            # å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œå°è¯•é‡è¯•ä¸€æ¬¡
            if "timeout" in str(e).lower() or "connection" in str(e).lower():
                print("ğŸ”„ æ£€æµ‹åˆ°ç½‘ç»œé—®é¢˜ï¼Œå°è¯•é‡è¯•...")
                try:
                    response = self.client.chat.completions.create(
                        model=self.model_name,
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {
                                        "type": "image_url",
                                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                                    }
                                ]
                            }
                        ],
                        max_tokens=600,
                        temperature=0.7,
                        timeout=20  # å¢åŠ è¶…æ—¶æ—¶é—´
                    )
                    
                    response_text = response.choices[0].message.content.strip()
                    print(f"ğŸ¤– é‡è¯•æˆåŠŸï¼ŒAIåŸå§‹å“åº”: {response_text[:200]}...")
                    
                    # å°è¯•è§£æJSON
                    try:
                        json_text = self._extract_json_from_response(response_text)
                        ai_data = json.loads(json_text)
                        
                        if 'suggestions' in ai_data and isinstance(ai_data['suggestions'], list):
                            validated_suggestions = []
                            for suggestion in ai_data['suggestions']:
                                if isinstance(suggestion, dict) and 'action' in suggestion and 'direction' in suggestion:
                                    validated_suggestions.append({
                                        "step": suggestion.get('step', len(validated_suggestions) + 1),
                                        "action": suggestion['action'],
                                        "direction": self._validate_direction(suggestion['direction']),
                                        "intensity": self._validate_intensity(suggestion.get('intensity', 3)),
                                        "reason": suggestion.get('reason', 'åŸºäºç”»é¢åˆ†æ')
                                    })
                            
                            if validated_suggestions:
                                # æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•ï¼ˆé‡è¯•æˆåŠŸï¼‰
                                self.add_to_message_history("user", prompt, base64_image)
                                self.add_to_message_history("assistant", response_text)
                                
                                self.set_cached_result(cache_key, validated_suggestions)
                                return validated_suggestions
                    except:
                        pass
                except Exception as retry_error:
                    print(f"âŒ é‡è¯•ä¹Ÿå¤±è´¥äº†: {retry_error}")
        
        # è¿”å›é»˜è®¤å»ºè®®
        fallback_result = self._get_fallback_suggestions()
        self.set_cached_result(cache_key, fallback_result)
        return fallback_result
    
    def _extract_json_from_response(self, response_text: str) -> str:
        """ä»AIå“åº”ä¸­æå–JSONéƒ¨åˆ†"""
        # ç§»é™¤```json```æ ‡è®°
        if '```json' in response_text:
            start = response_text.find('```json') + 7
            end = response_text.find('```', start)
            if end != -1:
                return response_text[start:end].strip()
        elif '```' in response_text:
            start = response_text.find('```') + 3
            end = response_text.find('```', start)
            if end != -1:
                return response_text[start:end].strip()
        
        # å°è¯•æ‰¾åˆ°JSONå¯¹è±¡
        start = response_text.find('{')
        end = response_text.rfind('}')
        if start != -1 and end != -1 and end > start:
            return response_text[start:end+1]
        
        return response_text.strip()
    
    def _validate_direction(self, direction: str) -> str:
        """éªŒè¯å¹¶æ ‡å‡†åŒ–æ–¹å‘"""
        valid_directions = ['up', 'down', 'left', 'right', 'left_up', 'left_down', 'right_up', 'right_down']
        
        direction = direction.lower().strip()
        
        if direction in valid_directions:
            return direction
        
        # æ˜ å°„ä¸€äº›å¸¸è§çš„é”™è¯¯æ ¼å¼
        direction_mapping = {
            'upward': 'up', 'upwards': 'up', 'ä¸Š': 'up', 'å‘ä¸Š': 'up',
            'downward': 'down', 'downwards': 'down', 'ä¸‹': 'down', 'å‘ä¸‹': 'down',
            'leftward': 'left', 'leftwards': 'left', 'å·¦': 'left', 'å‘å·¦': 'left',
            'rightward': 'right', 'rightwards': 'right', 'å³': 'right', 'å‘å³': 'right',
            'left-up': 'left_up', 'leftup': 'left_up', 'å·¦ä¸Š': 'left_up',
            'left-down': 'left_down', 'leftdown': 'left_down', 'å·¦ä¸‹': 'left_down',
            'right-up': 'right_up', 'rightup': 'right_up', 'å³ä¸Š': 'right_up',
            'right-down': 'right_down', 'rightdown': 'right_down'
        }
        
        return direction_mapping.get(direction, 'up')  # é»˜è®¤è¿”å›'up'
    
    def _validate_intensity(self, intensity) -> int:
        """éªŒè¯å¹¶æ ‡å‡†åŒ–å¼ºåº¦å€¼"""
        try:
            intensity_val = int(intensity)
            # ç¡®ä¿åœ¨1-5èŒƒå›´å†…
            if 1 <= intensity_val <= 5:
                return intensity_val
            else:
                return 3  # é»˜è®¤ä¸­ç­‰å¼ºåº¦
        except (ValueError, TypeError):
            return 3  # é»˜è®¤ä¸­ç­‰å¼ºåº¦
    
    def _parse_text_to_suggestions(self, text: str) -> list:
        """å°†æ–‡æœ¬æ ¼å¼çš„å»ºè®®è½¬æ¢ä¸ºJSONæ ¼å¼ï¼ˆé™çº§å¤„ç†ï¼‰"""
        suggestions = []
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            if line and (line[0].isdigit() or '.' in line[:3]):
                # æå–åŠ¨ä½œæè¿°
                action = line
                if '. ' in action:
                    action = action.split('. ', 1)[1]
                
                # ç®€å•çš„æ–¹å‘æ¨æ–­
                direction = 'up'  # é»˜è®¤æ–¹å‘
                if any(word in action.lower() for word in ['å·¦', 'left', 'å¾€å·¦']):
                    direction = 'left'
                elif any(word in action.lower() for word in ['å³', 'right', 'å¾€å³']):
                    direction = 'right'
                elif any(word in action.lower() for word in ['è¹²', 'down', 'é™ä½', 'å‘ä¸‹']):
                    direction = 'down'
                elif any(word in action.lower() for word in ['ç«™', 'up', 'ä¸¾é«˜', 'å‘ä¸Š']):
                    direction = 'up'
                
                # ç®€å•çš„å¼ºåº¦æ¨æ–­
                intensity = 3  # é»˜è®¤ä¸­ç­‰å¼ºåº¦
                action_lower = action.lower()
                if any(word in action_lower for word in ['ç¨å¾®', 'ä¸€ç‚¹ç‚¹', 'è½»å¾®']):
                    intensity = 1
                elif any(word in action_lower for word in ['ä¸€ç‚¹', '1æ­¥', 'å°å¹…']):
                    intensity = 2
                elif any(word in action_lower for word in ['2æ­¥', '3æ­¥', 'å‡ æ­¥']):
                    intensity = 3
                elif any(word in action_lower for word in ['4æ­¥', '5æ­¥', 'è¾ƒå¤§', 'å¤š']):
                    intensity = 4
                elif any(word in action_lower for word in ['å¾ˆå¤š', 'å¤§å¹…', 'å¤§é‡', 'å¾ˆå¤§']):
                    intensity = 5
                
                suggestions.append({
                    "step": len(suggestions) + 1,
                    "action": action,
                    "direction": direction,
                    "intensity": intensity,
                    "reason": "åŸºäºåŠ¨ä½œæè¿°æ¨æ–­"
                })
                
                if len(suggestions) >= 4:  # æœ€å¤š4æ¡å»ºè®®
                    break
        
        return suggestions
    
    def _get_fallback_suggestions(self) -> list:
        """è·å–é»˜è®¤å»ºè®®ï¼ˆå½“AIå¤±è´¥æ—¶ï¼‰"""
        return [
            {
                "step": 1,
                "action": "è°ƒæ•´æ‹æ‘„è§’åº¦ï¼Œå¯»æ‰¾æœ€ä½³æ„å›¾ä½ç½®",
                "direction": "left",
                "intensity": 3,
                "reason": "ä¼˜åŒ–æ„å›¾å¸ƒå±€"
            },
            {
                "step": 2,
                "action": "è°ƒæ•´æ‹æ‘„é«˜åº¦ï¼Œå°è¯•ä¸åŒè§†è§’",
                "direction": "down",
                "intensity": 2,
                "reason": "å¢åŠ ç”»é¢å±‚æ¬¡æ„Ÿ"
            },
            {
                "step": 3,
                "action": "è°ƒæ•´ç„¦è·ï¼Œçªå‡ºä¸»ä½“å…ƒç´ ",
                "direction": "up",
                "intensity": 2,
                "reason": "å¢å¼ºä¸»ä½“è¡¨ç°åŠ›"
            },
            {
                "step": 4,
                "action": "å¾®è°ƒä½ç½®ï¼Œå¹³è¡¡ç”»é¢å…ƒç´ ",
                "direction": "right",
                "intensity": 2,
                "reason": "å®Œå–„æ•´ä½“æ„å›¾"
            }
        ]

def main():
    """æµ‹è¯•æ‘„å½±agent"""
    import sys
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
    else:
        image_path = "test.jpg"  # é»˜è®¤å›¾ç‰‡
    
    print("ğŸ¯ æ‰‹æœºæ‘„å½±Agentæ¼”ç¤º")
    print("ç‰¹ç‚¹: OpenCVç²¾ç¡®æ°´å¹³æ£€æµ‹ + AIè§†è§‰ç†è§£")
    print("="*60)
    
    agent = PhotographyAgent()
    
    if os.path.exists(image_path):
        print(f"\nğŸ“¸ åˆ†ææµ‹è¯•å›¾ç‰‡: {image_path}")
        guidance = agent.get_guidance(image_path)
        print(f"\nğŸ’¡ æ‹æ‘„å»ºè®®:")
        print(guidance)
        
        print(f"\nğŸ”§ æŠ€æœ¯è¯´æ˜:")
        analysis = agent.analyze_image(image_path)
        if not analysis.get('is_level', True):
            tilt_direction = analysis.get('tilt_direction', 'level')
            tilt_angle = analysis.get('tilt_angle', 0)
            print(f"- OpenCVæ£€æµ‹: {tilt_direction}ï¼ˆ{tilt_angle}åº¦ï¼‰")
            if tilt_direction == 'left_high':
                print("- æ­£ç¡®æŒ‡ä»¤: å³æ‰‹æŠ¬èµ·æ¥ï¼ˆå·¦è¾¹é«˜éœ€è¦æŠ¬å³æ‰‹ï¼‰")
            elif tilt_direction == 'right_high':
                print("- æ­£ç¡®æŒ‡ä»¤: å·¦æ‰‹æŠ¬èµ·æ¥ï¼ˆå³è¾¹é«˜éœ€è¦æŠ¬å·¦æ‰‹ï¼‰")
        else:
            print("- OpenCVè®¤ä¸ºåŸºæœ¬æ°´å¹³ï¼ŒAIè¿›è¡ŒäºŒæ¬¡æ£€æŸ¥")
    else:
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ {image_path} ä¸å­˜åœ¨")
        print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: python photography_agent.py [å›¾ç‰‡è·¯å¾„]")
        print(f"ğŸ’¡ ç¤ºä¾‹: python photography_agent.py my_photo.jpg")

if __name__ == "__main__":
    main() 